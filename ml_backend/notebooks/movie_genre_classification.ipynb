{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification - For movies and webseries\n",
    "**In this notebook we will try the following approaches for training machine learning models for text classification:**\n",
    "1. Text classification using TFIDF, CountVectorizer and Spacy\n",
    "2. Text classification using spacy, and Spacy's inbuilt word embeddings\n",
    "2. Text classification using Spacy and Gensim models (Like google-news-300 & twitter-25)\n",
    "3. Text classification using Spacy and fasttext (by meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Not considering Decision Trees (Prone to overfit)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data_sets/rotten_tomatoes_100.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason's Lyric</td>\n",
       "      <td>In a violent, drug-infested neighborhood in Ho...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chocolat</td>\n",
       "      <td>When mysterious Vianne and her child arrive in...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pretty Woman</td>\n",
       "      <td>A prostitute and a wealthy businessman fall fo...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love Actually</td>\n",
       "      <td>Nine intertwined stories examine the complexit...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Affair to Remember</td>\n",
       "      <td>A man and a woman have a romance while on a cr...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                           synopsis  \\\n",
       "0          Jason's Lyric  In a violent, drug-infested neighborhood in Ho...   \n",
       "1               Chocolat  When mysterious Vianne and her child arrive in...   \n",
       "2           Pretty Woman  A prostitute and a wealthy businessman fall fo...   \n",
       "3          Love Actually  Nine intertwined stories examine the complexit...   \n",
       "4  An Affair to Remember  A man and a woman have a romance while on a cr...   \n",
       "\n",
       "      label  \n",
       "0  romantic  \n",
       "1  romantic  \n",
       "2  romantic  \n",
       "3  romantic  \n",
       "4  romantic  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['romantic', 'thriller', 'action', 'horror', 'sci-fi', 'drama'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].replace(\"sci-fi\",\"scifi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training and evaluating the base form of classification algorithms on the dataset\n",
    "This will give us an idea that what kind of approaches we can further implement to improve the performance. \n",
    "\n",
    "**Approach:**  \n",
    "Here we will simply preprocess the dataset using spacy language pipline, creating a vocabulary using the word vectorizers, fitting the models and then evaluating the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the spacy language pipleine\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocsessing the text data of synopsis\n",
    "def preprocess(text, spacy_model=nlp):\n",
    "    \"\"\"Pass a text and it will preprocess it!\"\"\"\n",
    "    filtered = []\n",
    "    doc = spacy_model(text)\n",
    "    for token in doc:\n",
    "        if (not token.is_stop) and (not token.is_punct):\n",
    "            filtered.append(token.text)\n",
    "\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training and evaluating the classification algorithms\n",
    "# (With default hyper parameters)\n",
    "def base_train_eval(models, X, y, tsize=0.20, rstate=45, \n",
    "                    vec_type=\"tfidf\", acc=True, cfreport=True, show_vocab=True, max_performer=True,\n",
    "                    complete_res=True):\n",
    "    \n",
    "    eval_res = {} # Results of evaluation process\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize, random_state=rstate)\n",
    "    if vec_type == \"tfidf\":\n",
    "        vec = TfidfVectorizer()\n",
    "    elif vec_type == \"count\":\n",
    "        vec = CountVectorizer()\n",
    "    else:\n",
    "        print(\"Enter a valid string for choosing the vectorizer!\")\n",
    "        return # terminates here\n",
    "    \n",
    "    vec.fit(X_train)\n",
    "    spX_train = vec.transform(X_train)\n",
    "    spX_test = vec.transform(X_test)\n",
    "\n",
    "    if show_vocab == True:\n",
    "        # bow = vec.vocabulary_ (each word is mapped to an index)\n",
    "        bow = vec.get_feature_names_out()[200:300] # Just a glimpse of BOW\n",
    "        print(\"\\n---> Given below is the BOW:\\n\")\n",
    "        print(bow)\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n----> Classification report of the classification algorithms\")\n",
    "    for model in models:\n",
    "        model.fit(spX_train, y_train)\n",
    "        preds = model.predict(spX_test)\n",
    "\n",
    "        print(f\"Model Name: {model}\")\n",
    "        if acc == True:\n",
    "            acc_score = accuracy_score(y_true=y_test, y_pred=preds)\n",
    "            print(f\"Overall accuracy: {round(acc_score * 100, 2)} %\")\n",
    "        if cfreport == True:\n",
    "            report = classification_report(y_true=y_test, y_pred=preds)\n",
    "            print(f\"Classification report:\\n{report}\")\n",
    "        if max_performer == True:\n",
    "            eval_res[str(model)] = round(acc_score * 100, 2)\n",
    "\n",
    "    if complete_res == True:\n",
    "        print(\"Complete results for all algorithms:\")\n",
    "        print(eval_res)\n",
    "\n",
    "    if max_performer == True:\n",
    "        max_a = 0 \n",
    "        max_p = \"\"\n",
    "        for model in eval_res:\n",
    "            if eval_res[model] > max_a:\n",
    "                max_a = eval_res[model]\n",
    "                max_p = model\n",
    "        # print(f\"\\n\\n---> Max performer: {max_p}\")\n",
    "        # print(f\"---> Overall accuracy of this model: {max_a}\")\n",
    "\n",
    "        return max_p, max_a # return max performer and it's accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function we just prepared and training and evaluating the base algorithms\n",
    "df[\"processed_synop\"] = df[\"synopsis\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_synop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason's Lyric</td>\n",
       "      <td>In a violent, drug-infested neighborhood in Ho...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>violent drug infested neighborhood Houston Jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chocolat</td>\n",
       "      <td>When mysterious Vianne and her child arrive in...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>mysterious Vianne child arrive tranquil French...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pretty Woman</td>\n",
       "      <td>A prostitute and a wealthy businessman fall fo...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>prostitute wealthy businessman fall forming un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love Actually</td>\n",
       "      <td>Nine intertwined stories examine the complexit...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>intertwined stories examine complexities emoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Affair to Remember</td>\n",
       "      <td>A man and a woman have a romance while on a cr...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>man woman romance cruise Europe New York Despi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                           synopsis  \\\n",
       "0          Jason's Lyric  In a violent, drug-infested neighborhood in Ho...   \n",
       "1               Chocolat  When mysterious Vianne and her child arrive in...   \n",
       "2           Pretty Woman  A prostitute and a wealthy businessman fall fo...   \n",
       "3          Love Actually  Nine intertwined stories examine the complexit...   \n",
       "4  An Affair to Remember  A man and a woman have a romance while on a cr...   \n",
       "\n",
       "      label                                    processed_synop  \n",
       "0  romantic  violent drug infested neighborhood Houston Jas...  \n",
       "1  romantic  mysterious Vianne child arrive tranquil French...  \n",
       "2  romantic  prostitute wealthy businessman fall forming un...  \n",
       "3  romantic  intertwined stories examine complexities emoti...  \n",
       "4  romantic  man woman romance cruise Europe New York Despi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Now the df will have a new column with processed synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNOPSIS: In a violent, drug-infested neighborhood in Houston, Jason (Allen Payne) dreams of something better. He works as a TV salesman and helps out his mother, and tries to steer his criminally minded brother, Joshua (Bokeem Woodbine), onto the right path. But real joy enters Jason's life when he meets Lyric (Jada Pinkett). As their romance develops, Jason starts to see a future for himself -- while also being forced to confront a painful secret from his past.\n",
      "PROCESSED SYNOPSIS: violent drug infested neighborhood Houston Jason Allen Payne dreams better works TV salesman helps mother tries steer criminally minded brother Joshua Bokeem Woodbine right path real joy enters Jason life meets Lyric Jada Pinkett romance develops Jason starts future forced confront painful secret past\n"
     ]
    }
   ],
   "source": [
    "print(f\"SYNOPSIS: {df[\"synopsis\"][0]}\")\n",
    "print(f\"PROCESSED SYNOPSIS: {df[\"processed_synop\"][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Given below is the BOW:\n",
      "\n",
      "['aircraft' 'airport' 'aja' 'akin' 'alan' 'alarum' 'alaskan' 'alba'\n",
      " 'albright' 'alcaino' 'alcohol' 'alden' 'alejandro' 'aleksandr' 'alerting'\n",
      " 'alessio' 'alex' 'alexander' 'alexandre' 'algerian' 'algout' 'ali'\n",
      " 'alice' 'alicia' 'alien' 'aliens' 'alike' 'alita' 'alive' 'allegiances'\n",
      " 'allen' 'alleviate' 'alliance' 'alliances' 'allied' 'allies' 'allow'\n",
      " 'allowed' 'allows' 'alluring' 'ally' 'almasy' 'almighty' 'alongside'\n",
      " 'aloof' 'alter' 'altered' 'altering' 'alternate' 'alternative'\n",
      " 'alzheimer' 'amanda' 'amateur' 'ambassadors' 'amber' 'ambition'\n",
      " 'ambitious' 'ambitiously' 'ambush' 'ambushed' 'amelia' 'america'\n",
      " 'american' 'amiable' 'amid' 'amidst' 'amitabh' 'amy' 'amélie' 'am茅lie'\n",
      " 'ana' 'analyst' 'anand' 'anarchic' 'anatoliy' 'ancestor' 'ancestral'\n",
      " 'anchors' 'ancient' 'and' 'andrew' 'andrews' 'androids' 'andré' 'andy'\n",
      " 'aneta' 'angel' 'angela' 'angeles' 'animals' 'animated' 'animator'\n",
      " 'animatronic' 'anime' 'anjali' 'ann' 'anna' 'anne' 'annie' 'annihilation']\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 34.71 %\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.67      0.21      0.32        19\n",
      "       drama       0.20      0.09      0.12        23\n",
      "      horror       0.60      0.33      0.43        18\n",
      "    romantic       0.47      0.53      0.50        17\n",
      "       scifi       1.00      0.38      0.55        29\n",
      "    thriller       0.15      0.67      0.25        15\n",
      "\n",
      "    accuracy                           0.35       121\n",
      "   macro avg       0.52      0.37      0.36       121\n",
      "weighted avg       0.56      0.35      0.37       121\n",
      "\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 38.02 %\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.41      0.37      0.39        19\n",
      "       drama       0.35      0.26      0.30        23\n",
      "      horror       0.44      0.44      0.44        18\n",
      "    romantic       0.39      0.65      0.49        17\n",
      "       scifi       0.77      0.34      0.48        29\n",
      "    thriller       0.14      0.27      0.19        15\n",
      "\n",
      "    accuracy                           0.38       121\n",
      "   macro avg       0.42      0.39      0.38       121\n",
      "weighted avg       0.46      0.38      0.39       121\n",
      "\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 40.5 %\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.44      0.21      0.29        19\n",
      "       drama       0.42      0.22      0.29        23\n",
      "      horror       0.33      0.39      0.36        18\n",
      "    romantic       0.52      0.88      0.65        17\n",
      "       scifi       0.67      0.48      0.56        29\n",
      "    thriller       0.14      0.27      0.18        15\n",
      "\n",
      "    accuracy                           0.40       121\n",
      "   macro avg       0.42      0.41      0.39       121\n",
      "weighted avg       0.45      0.40      0.40       121\n",
      "\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 39.67 %\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.55      0.32      0.40        19\n",
      "       drama       0.46      0.26      0.33        23\n",
      "      horror       0.43      0.50      0.46        18\n",
      "    romantic       0.35      0.53      0.42        17\n",
      "       scifi       0.88      0.48      0.62        29\n",
      "    thriller       0.12      0.27      0.16        15\n",
      "\n",
      "    accuracy                           0.40       121\n",
      "   macro avg       0.46      0.39      0.40       121\n",
      "weighted avg       0.51      0.40      0.42       121\n",
      "\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 35.54 %\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.50      0.21      0.30        19\n",
      "       drama       0.60      0.13      0.21        23\n",
      "      horror       0.30      0.39      0.34        18\n",
      "    romantic       0.54      0.88      0.67        17\n",
      "       scifi       0.69      0.31      0.43        29\n",
      "    thriller       0.11      0.33      0.17        15\n",
      "\n",
      "    accuracy                           0.36       121\n",
      "   macro avg       0.46      0.38      0.35       121\n",
      "weighted avg       0.49      0.36      0.36       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_p, max_a = base_train_eval(\n",
    "    models=[\n",
    "        AdaBoostClassifier(algorithm=\"SAMME\"),\n",
    "        GradientBoostingClassifier(),\n",
    "        LogisticRegression(),\n",
    "        RandomForestClassifier(),\n",
    "        MultinomialNB()\n",
    "    ],\n",
    "    X=df[\"processed_synop\"],\n",
    "    y=df[\"label\"],\n",
    "    tsize=0.20,\n",
    "    rstate=455,\n",
    "    vec_type=\"tfidf\",\n",
    "    acc=True, cfreport=True, show_vocab=True,\n",
    "    max_performer=True,\n",
    "    complete_res=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max performer: LogisticRegression()\n",
      "It's overall accyracy: 40.5\n"
     ]
    }
   ],
   "source": [
    "# Let's print the returned max performer and it's accuracy\n",
    "print(f\"Max performer: {max_p}\")\n",
    "print(f\"It's overall accyracy: {max_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Performance is very poor as compared what we saw in the reports of the data testing part. It was performing good in binary classification, but in multiclass classification, it is performing poorly. And this might be because of our data. The data is not enough to train a model on the entire dataset performing a multiclass classification with good results.\n",
    "\n",
    "However there's another the approach we can try. We can combine multiple binary classification to form a single multi-class classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Combining multiple binary class classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['romantic', 'thriller', 'action', 'horror', 'scifi', 'drama'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional filtering for two classes\n",
    "def pdcond_filter(c1, c2, df, y):\n",
    "    filt_df = df[(df[y]==c1) | (df[y]==c2)]\n",
    "\n",
    "# Function to find the best pair of labels...\n",
    "# Pairs on which the model performs binary classification with good results\n",
    "def pairs_train_eval(X, y, label_col, synop_col, models=None, \n",
    "                     tsize=0.20, rstate=45, vec_type=\"tfidf\", acc=True,\n",
    "                     cfreport=True, show_vocab=True, max_performer=True, complete_res=True,\n",
    "                     data=df):\n",
    "    label_pairs = set()\n",
    "    all_labels = list(y.unique())\n",
    "    for label in all_labels:\n",
    "        label_current = label\n",
    "        for label in all_labels:\n",
    "            if label_current != label:\n",
    "                pair = str(label_current) + \"-\" + str(label)\n",
    "                label_pairs.add(pair)\n",
    "\n",
    "    label_pairs = list(label_pairs)\n",
    "    final_res = {} # Final result from the train & eval\n",
    "    for i, lb in enumerate(label_pairs):\n",
    "        lb1 = lb.split(\"-\")[0]\n",
    "        lb2 = lb.split(\"-\")[1]\n",
    "        filt_data = data[(data[label_col]==lb1) | (data[label_col]==lb2)] # filtered segment\n",
    "\n",
    "        print(f\"\\n\\n---> Pair-{i + 1}, Pair Name: {lb}\\n\\n\")\n",
    "        max_p, max_a = base_train_eval(\n",
    "            models=models,\n",
    "            X=filt_data[synop_col],\n",
    "            y=filt_data[label_col],\n",
    "            tsize=tsize,\n",
    "            rstate=rstate,\n",
    "            vec_type=vec_type,\n",
    "            acc=acc,\n",
    "            cfreport=cfreport,\n",
    "            show_vocab=show_vocab,\n",
    "            max_performer=max_performer,\n",
    "            complete_res=complete_res\n",
    "        )\n",
    "\n",
    "        final_res[lb] = f\"{max_p}  <---> {max_a:.2f}\"\n",
    "        # filt_data = data[(data[y]==lb1) | (data[y]==lb2)]\n",
    "        # print(filt_data.sample(10)[])\n",
    "        # print(lb1,lb2)\n",
    "\n",
    "    return final_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---> Pair-1, Pair Name: scifi-drama\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 64.29 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 64.29 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 85.71 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 73.81 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 83.33 %\n",
      "\n",
      "\n",
      "---> Pair-2, Pair Name: drama-romantic\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 75.61 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 63.41 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 80.49 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 65.85 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 75.61 %\n",
      "\n",
      "\n",
      "---> Pair-3, Pair Name: drama-horror\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 60.0 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 67.5 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 70.0 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 75.0 %\n",
      "\n",
      "\n",
      "---> Pair-4, Pair Name: scifi-romantic\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 80.49 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 75.61 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 90.24 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 85.37 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 90.24 %\n",
      "\n",
      "\n",
      "---> Pair-5, Pair Name: romantic-action\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 75.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 90.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 80.0 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 92.5 %\n",
      "\n",
      "\n",
      "---> Pair-6, Pair Name: drama-scifi\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 64.29 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 64.29 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 85.71 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 76.19 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 83.33 %\n",
      "\n",
      "\n",
      "---> Pair-7, Pair Name: drama-thriller\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 53.66 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 53.66 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 53.66 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 51.22 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 58.54 %\n",
      "\n",
      "\n",
      "---> Pair-8, Pair Name: thriller-scifi\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 70.73 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 68.29 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 65.85 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 65.85 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 68.29 %\n",
      "\n",
      "\n",
      "---> Pair-9, Pair Name: horror-action\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 56.41 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 66.67 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 56.41 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 64.1 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 66.67 %\n",
      "\n",
      "\n",
      "---> Pair-10, Pair Name: action-romantic\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 75.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 90.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 77.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 92.5 %\n",
      "\n",
      "\n",
      "---> Pair-11, Pair Name: action-horror\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 61.54 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 66.67 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 56.41 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 66.67 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 66.67 %\n",
      "\n",
      "\n",
      "---> Pair-12, Pair Name: horror-romantic\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 70.0 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 70.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 95.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 82.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 92.5 %\n",
      "\n",
      "\n",
      "---> Pair-13, Pair Name: horror-scifi\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 73.17 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 78.05 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 80.49 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 82.93 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 87.8 %\n",
      "\n",
      "\n",
      "---> Pair-14, Pair Name: drama-action\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 67.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 55.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 65.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 60.0 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 67.5 %\n",
      "\n",
      "\n",
      "---> Pair-15, Pair Name: scifi-thriller\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 70.73 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 68.29 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 65.85 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 65.85 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 68.29 %\n",
      "\n",
      "\n",
      "---> Pair-16, Pair Name: scifi-action\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 60.98 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 70.73 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 63.41 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 58.54 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 68.29 %\n",
      "\n",
      "\n",
      "---> Pair-17, Pair Name: action-drama\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 67.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 55.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 65.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 57.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 67.5 %\n",
      "\n",
      "\n",
      "---> Pair-18, Pair Name: thriller-horror\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 47.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 55.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 70.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 52.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 67.5 %\n",
      "\n",
      "\n",
      "---> Pair-19, Pair Name: romantic-scifi\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 80.49 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 75.61 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 90.24 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 90.24 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 90.24 %\n",
      "\n",
      "\n",
      "---> Pair-20, Pair Name: thriller-action\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 55.0 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 57.5 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 47.5 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 50.0 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 47.5 %\n",
      "\n",
      "\n",
      "---> Pair-21, Pair Name: scifi-horror\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 73.17 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 78.05 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 80.49 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 73.17 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 87.8 %\n",
      "\n",
      "\n",
      "---> Pair-22, Pair Name: romantic-drama\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 75.61 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 63.41 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 80.49 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 73.17 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 75.61 %\n",
      "\n",
      "\n",
      "---> Pair-23, Pair Name: action-thriller\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 57.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 57.5 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 47.5 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 50.0 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 47.5 %\n",
      "\n",
      "\n",
      "---> Pair-24, Pair Name: thriller-romantic\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 75.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 92.5 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 82.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 95.0 %\n",
      "\n",
      "\n",
      "---> Pair-25, Pair Name: thriller-drama\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 51.22 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 53.66 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 53.66 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 48.78 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 58.54 %\n",
      "\n",
      "\n",
      "---> Pair-26, Pair Name: romantic-horror\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 95.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 87.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 92.5 %\n",
      "\n",
      "\n",
      "---> Pair-27, Pair Name: horror-thriller\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 47.5 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 55.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 70.0 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 55.0 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 67.5 %\n",
      "\n",
      "\n",
      "---> Pair-28, Pair Name: romantic-thriller\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 75.0 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 75.0 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 92.5 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 87.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 95.0 %\n",
      "\n",
      "\n",
      "---> Pair-29, Pair Name: action-scifi\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 60.98 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 70.73 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 63.41 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 60.98 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 68.29 %\n",
      "\n",
      "\n",
      "---> Pair-30, Pair Name: horror-drama\n",
      "\n",
      "\n",
      "\n",
      "----> Classification report of the classification algorithms\n",
      "Model Name: GradientBoostingClassifier()\n",
      "Overall accuracy: 60.0 %\n",
      "Model Name: AdaBoostClassifier(algorithm='SAMME')\n",
      "Overall accuracy: 67.5 %\n",
      "Model Name: LogisticRegression()\n",
      "Overall accuracy: 72.5 %\n",
      "Model Name: RandomForestClassifier()\n",
      "Overall accuracy: 67.5 %\n",
      "Model Name: MultinomialNB()\n",
      "Overall accuracy: 75.0 %\n"
     ]
    }
   ],
   "source": [
    "final_res = pairs_train_eval(\n",
    "    X=df[\"processed_synop\"],\n",
    "    y=df[\"label\"], \n",
    "    label_col=\"label\",\n",
    "    synop_col=\"processed_synop\",\n",
    "    models=[\n",
    "        GradientBoostingClassifier(), \n",
    "        AdaBoostClassifier(algorithm=\"SAMME\"),\n",
    "        LogisticRegression(),\n",
    "        RandomForestClassifier(),\n",
    "        MultinomialNB()\n",
    "    ],\n",
    "    tsize=0.20, \n",
    "    rstate=45, \n",
    "    vec_type=\"tfidf\",\n",
    "    acc=True, \n",
    "    cfreport=False, show_vocab=False,\n",
    "    max_performer=True, complete_res=False, data=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scifi-drama': 'LogisticRegression()  <---> 85.71',\n",
       " 'drama-romantic': 'LogisticRegression()  <---> 80.49',\n",
       " 'drama-horror': 'MultinomialNB()  <---> 75.00',\n",
       " 'scifi-romantic': 'LogisticRegression()  <---> 90.24',\n",
       " 'romantic-action': 'MultinomialNB()  <---> 92.50',\n",
       " 'drama-scifi': 'LogisticRegression()  <---> 85.71',\n",
       " 'drama-thriller': 'MultinomialNB()  <---> 58.54',\n",
       " 'thriller-scifi': 'GradientBoostingClassifier()  <---> 70.73',\n",
       " 'horror-action': \"AdaBoostClassifier(algorithm='SAMME')  <---> 66.67\",\n",
       " 'action-romantic': 'MultinomialNB()  <---> 92.50',\n",
       " 'action-horror': \"AdaBoostClassifier(algorithm='SAMME')  <---> 66.67\",\n",
       " 'horror-romantic': 'LogisticRegression()  <---> 95.00',\n",
       " 'horror-scifi': 'MultinomialNB()  <---> 87.80',\n",
       " 'drama-action': 'GradientBoostingClassifier()  <---> 67.50',\n",
       " 'scifi-thriller': 'GradientBoostingClassifier()  <---> 70.73',\n",
       " 'scifi-action': \"AdaBoostClassifier(algorithm='SAMME')  <---> 70.73\",\n",
       " 'action-drama': 'GradientBoostingClassifier()  <---> 67.50',\n",
       " 'thriller-horror': 'LogisticRegression()  <---> 70.00',\n",
       " 'romantic-scifi': 'LogisticRegression()  <---> 90.24',\n",
       " 'thriller-action': \"AdaBoostClassifier(algorithm='SAMME')  <---> 57.50\",\n",
       " 'scifi-horror': 'MultinomialNB()  <---> 87.80',\n",
       " 'romantic-drama': 'LogisticRegression()  <---> 80.49',\n",
       " 'action-thriller': 'GradientBoostingClassifier()  <---> 57.50',\n",
       " 'thriller-romantic': 'MultinomialNB()  <---> 95.00',\n",
       " 'thriller-drama': 'MultinomialNB()  <---> 58.54',\n",
       " 'romantic-horror': 'LogisticRegression()  <---> 95.00',\n",
       " 'horror-thriller': 'LogisticRegression()  <---> 70.00',\n",
       " 'romantic-thriller': 'MultinomialNB()  <---> 95.00',\n",
       " 'action-scifi': \"AdaBoostClassifier(algorithm='SAMME')  <---> 70.73\",\n",
       " 'horror-drama': 'MultinomialNB()  <---> 75.00'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarizing the best results:**\n",
    "\n",
    "|S.No.|Pair|Acc|Algo|\n",
    "|-----|----|---|----|\n",
    "|1|r-d|80.49|logistic|\n",
    "|2|r-h|95.00|logistic|\n",
    "|3|r-a|92.50|naive bayes|\n",
    "|4|s-h|87.80|naive bayes|\n",
    "|5|r-s|90.24|logistic|\n",
    "|6|s-d|85.71|logistic|\n",
    "|7|r-t|95.00|naive bayes|\n",
    "\n",
    "**We will consider sno 1, 2, 3, 5, and 7.** And combine the result of these models and see if it works.\n",
    "\n",
    "**IMPORTANT NOTE:-**  \n",
    "It's not like we exactly stick to this table and the huge report we generated of each pair, but we can use this as a reference to make generalized model for each pair, and then combine them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training (fine tuning if needed) models for the mentioned pairs. And then combining the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyper parameter grid for logistic regresion models\n",
    "param_grid = {\n",
    "    \"C\":np.logspace(1,30,20),\n",
    "    \"class_weight\":[None, \"balanced\"],\n",
    "    \"solver\":[\"liblinear\"],\n",
    "    \"max_iter\":[1000],\n",
    "    \"multi_class\":[\"ovr\"],\n",
    "}\n",
    "\n",
    "# We will not use elastic net penalty here\n",
    "# Because only \"saga\" solver supports elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is for the pair romantic-drama\n",
    "# Let's call it rd\n",
    "base_log = LogisticRegression()\n",
    "log_rd = GridSearchCV(\n",
    "    estimator=base_log,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<160x3378 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 5588 stored elements in Compressed Sparse Row format>,\n",
       " <41x3378 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 827 stored elements in Compressed Sparse Row format>,\n",
       " (160, 3378),\n",
       " (41, 3378))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's prepare the dataset for it and then fit the model\n",
    "df1 = df[(df[\"label\"]==\"romantic\") | (df[\"label\"]==\"drama\")]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    df1[\"processed_synop\"], df1[\"label\"], test_size=0.20, random_state=45\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X_train1)\n",
    "spX_train1 = tfidf.transform(X_train1)\n",
    "spX_test1 = tfidf.transform(X_test1)\n",
    "\n",
    "spX_train1, spX_test1, spX_train1.shape, spX_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overal Accuracy of log_rd model: 75.60975609756098 percent\n",
      "\n",
      "Classification report of log_rd model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drama       0.78      0.70      0.74        20\n",
      "    romantic       0.74      0.81      0.77        21\n",
      "\n",
      "    accuracy                           0.76        41\n",
      "   macro avg       0.76      0.75      0.75        41\n",
      "weighted avg       0.76      0.76      0.76        41\n",
      "\n",
      "\n",
      "Confusion matrix of log_rd model:\n",
      "[[14  6]\n",
      " [ 4 17]]\n"
     ]
    }
   ],
   "source": [
    "# Training the first model, of pair romantic-drama\n",
    "log_rd.fit(spX_train1, y_train1)\n",
    "preds_rd = log_rd.predict(spX_test1)\n",
    "\n",
    "acc_rd = accuracy_score(y_true=y_test1, y_pred=preds_rd)\n",
    "print(f\"Overal Accuracy of log_rd model: {acc_rd * 100} percent\")\n",
    "creport = classification_report(y_true=y_test1, y_pred=preds_rd)\n",
    "print(\"\\nClassification report of log_rd model:\")\n",
    "print(creport)\n",
    "\n",
    "print(\"\\nConfusion matrix of log_rd model:\")\n",
    "print(confusion_matrix(y_true=y_test1, y_pred=preds_rd))\n",
    "\n",
    "# Predictions are a little of than the base value!\n",
    "# Let's try out the default model once again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_rd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drama       0.80      0.80      0.80        20\n",
      "    romantic       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.80        41\n",
      "   macro avg       0.80      0.80      0.80        41\n",
      "weighted avg       0.80      0.80      0.80        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_log.fit(spX_train1, y_train1)\n",
    "base_preds = base_log.predict(spX_test1)\n",
    "print(classification_report(y_true=y_test1, y_pred=base_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_log.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  4],\n",
       "       [ 4, 17]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true=y_test1, y_pred=base_preds) # Confusion matrix for the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  We did try some hyper parameter tuning here, but default params of the model are performing better. So let's go with the default hyper params now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of log_rd: 0.8048780487804879\n",
      "Overall accuracy of log_rh: 0.95\n",
      "\n",
      "\n",
      "Classification report of log_rd:              precision    recall  f1-score   support\n",
      "\n",
      "       drama       0.80      0.80      0.80        20\n",
      "    romantic       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.80        41\n",
      "   macro avg       0.80      0.80      0.80        41\n",
      "weighted avg       0.80      0.80      0.80        41\n",
      "\n",
      "\n",
      "Classification report of log_rh:              precision    recall  f1-score   support\n",
      "\n",
      "      horror       1.00      0.90      0.95        20\n",
      "    romantic       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the logistic regression model for the pair 1 and 2\n",
    "# Pair 1 is r-d (romantic and drama)\n",
    "# Pair 2 is r-h (romantic and horror)\n",
    "\n",
    "log_rd = LogisticRegression()\n",
    "log_rh = LogisticRegression()\n",
    "\n",
    "df1 = df[(df[\"label\"]==\"romantic\") | (df[\"label\"]==\"drama\")]\n",
    "df2 = df[(df[\"label\"]==\"romantic\") | (df[\"label\"]==\"horror\")]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    df1[\"processed_synop\"], df1[\"label\"], test_size=0.20, random_state=45)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    df2[\"processed_synop\"], df2[\"label\"], test_size=0.20, random_state=45)\n",
    "\n",
    "# Fitting serparate vectorizer\n",
    "# Because vectorizers were serparate for each pair in our pair-function\n",
    "vec1 = TfidfVectorizer()\n",
    "vec1.fit(X_train1, y_train1)\n",
    "spX_train1 = vec1.transform(X_train1)\n",
    "spX_test1 = vec1.transform(X_test1)\n",
    "\n",
    "vec2 = TfidfVectorizer()\n",
    "vec2.fit(X_train2, y_train2)\n",
    "spX_train2 = vec2.transform(X_train2)\n",
    "spX_test2 = vec2.transform(X_test2)\n",
    "\n",
    "log_rd.fit(spX_train1, y_train1)\n",
    "log_rh.fit(spX_train2, y_train2)\n",
    "preds_rd = log_rd.predict(spX_test1)\n",
    "preds_rh = log_rh.predict(spX_test2)\n",
    "\n",
    "acc_log = accuracy_score(y_true=y_test1, y_pred=preds_rd)\n",
    "acc2 = accuracy_score(y_true=y_test2, y_pred=preds_rh)\n",
    "print(f\"Overall accuracy of log_rd: {acc_log}\")\n",
    "print(f\"Overall accuracy of log_rh: {acc2}\\n\")\n",
    "print(f\"\\nClassification report of log_rd:{classification_report(y_test1, preds_rd)}\")\n",
    "print(f\"\\nClassification report of log_rh:{classification_report(y_test2, preds_rh)}\")\n",
    "\n",
    "# Our second model seems to overfit a little!\n",
    "# Since all the best cases either Logistic regression algorithm or naive bayes was performing well...\n",
    "# We can try other algorithms like naive bayes on the same dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      horror       0.95      0.90      0.92        20\n",
      "    romantic       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n",
      "Accuracy of the nb model: 0.925\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(spX_train2, y_train2)\n",
    "nb_preds = nb.predict(spX_test2)\n",
    "print(classification_report(y_true=y_test2, y_pred=nb_preds))\n",
    "# The naive bayes here looks a bit generalized to what we saw in the logistic regression\n",
    "\n",
    "acc_nb = accuracy_score(y_true=y_test2, y_pred=nb_preds)\n",
    "print(f\"Accuracy of the nb model: {acc_nb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text: Jack Torrance Jack Nicholson winter caretaker isolated Overlook Hotel Colorado hoping cure writer block settles wife Wendy Shelley Duvall son Danny Danny Lloyd plagued psychic premonitions Jack writing goes Danny visions disturbing Jack discovers hotel dark secrets begins unravel homicidal maniac hell bent terrorizing family\n",
      "[[0.59164289 0.40835711]]\n"
     ]
    }
   ],
   "source": [
    "# Let's test the nb model \n",
    "text = \"Jack Torrance (Jack Nicholson) becomes winter caretaker at the isolated Overlook Hotel in Colorado, hoping to cure his writer's block. He settles in along with his wife, Wendy (Shelley Duvall), and his son, Danny (Danny Lloyd), who is plagued by psychic premonitions. As Jack's writing goes nowhere and Danny's visions become more disturbing, Jack discovers the hotel's dark secrets and begins to unravel into a homicidal maniac hell-bent on terrorizing his family.\"\n",
    "procesed_txt = preprocess(text=text)\n",
    "print(f\"Processed text: {procesed_txt}\")\n",
    "text_vec = vec2.transform([procesed_txt])\n",
    "output = nb.predict_proba(text_vec)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text: Hazel Grace Lancaster Shailene Woodley 16 year old cancer patient meets falls love Gus Waters Ansel Elgort similarly afflicted teen cancer support group Hazel feels Gus understands share acerbic wit love books especially Grace touchstone Imperial Affliction Peter Van Houten Gus scores invitation meet reclusive author Hazel embark adventure brief lives\n",
      "[[0.43679495 0.56320505]]\n"
     ]
    }
   ],
   "source": [
    "# Let's test our log model for romantic drama pair as well\n",
    "text = \"\"\"Hazel Grace Lancaster (Shailene Woodley), a 16-year-old cancer patient, meets and falls in love with Gus Waters (Ansel Elgort), a similarly afflicted teen from her cancer support group. Hazel feels that Gus really understands her. They both share the same acerbic wit and a love of books, especially Grace's touchstone, \"An Imperial Affliction\" by Peter Van Houten. When Gus scores an invitation to meet the reclusive author, he and Hazel embark on the adventure of their brief lives.\"\"\"\n",
    "\n",
    "procesed_txt = preprocess(text=text)\n",
    "print(f\"Processed text: {procesed_txt}\")\n",
    "text_vec = vec1.transform([procesed_txt]) # Use vec1 here\n",
    "output = log_rd.predict_proba(text_vec)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We tested both the models!** Both are performing fine! We can proceed further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of nb2: 0.925\n",
      "Classification report of nb2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.95      0.90      0.92        20\n",
      "    romantic       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So far we have trained our two models\n",
    "# For Romantic Drama part - With 80 percent accuracy (Logistic), log_rd \n",
    "# For Romantic Horror part - With 93 percent accyracy (Naive Bayes), nb\n",
    "# Let's move further!\n",
    "\n",
    "# Training on romantic - action pair\n",
    "df3 = df[(df[\"label\"]==\"romantic\") | (df[\"label\"]==\"action\")]\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(\n",
    "    df3[\"processed_synop\"], df3[\"label\"], test_size=0.20, random_state=45)\n",
    "\n",
    "vec3 = TfidfVectorizer()\n",
    "vec3.fit(X_train3)\n",
    "spX_train3 = vec3.transform(X_train3)\n",
    "spX_test3 = vec3.transform(X_test3)\n",
    "\n",
    "nb2 = MultinomialNB()\n",
    "nb2.fit(spX_train3, y_train3)\n",
    "nb2_preds = nb2.predict(spX_test3)\n",
    "acc_nb2 = accuracy_score(y_test3, nb2_preds)\n",
    "print(f\"Overall accuracy of nb2: {acc_nb2}\")\n",
    "print(f\"Classification report of nb2:\\n{classification_report(y_test3, nb2_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text: Tom Cruise Cameron Crowe reunite Jerry Maguire Vanilla Sky story young New York City publishing magnate finds unexpected roller coaster ride romance comedy suspicion love sex dreams mind bending search soul\n",
      "[[0.36991366 0.63008634]]\n"
     ]
    }
   ],
   "source": [
    "# Let's test our nb2 model\n",
    "text = \"\"\"Tom Cruise and Cameron Crowe reunite after \"Jerry Maguire\" for \"Vanilla Sky,\" the story of a young New York City publishing magnate who finds himself on an unexpected roller-coaster ride of romance, comedy, suspicion, love, sex and dreams in a mind-bending search for his soul.\"\"\"\n",
    "\n",
    "procesed_txt = preprocess(text=text)\n",
    "print(f\"Processed text: {procesed_txt}\")\n",
    "text_vec = vec3.transform([procesed_txt]) # Use vec3 here\n",
    "output = nb2.predict_proba(text_vec)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our nb2 model, which classifies romantic and action movies also works fine, and is a generalized model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849593495934961"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So far we have trained our 3 models\n",
    "# log_rd, nb, and nb2\n",
    "# Let's sum up and average their accuracy to get an overall accuracy (so far)\n",
    "(acc_log + acc_nb + acc_nb2) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So far we have achieved 88% accuracy! That's really good!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['romantic', 'thriller', 'action', 'horror', 'scifi', 'drama'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of log_rs model: LogisticRegression()\n",
      "Classification report of log_rs model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    romantic       1.00      0.81      0.89        21\n",
      "       scifi       0.83      1.00      0.91        20\n",
      "\n",
      "    accuracy                           0.90        41\n",
      "   macro avg       0.92      0.90      0.90        41\n",
      "weighted avg       0.92      0.90      0.90        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Moving over to our 4th model\n",
    "# Romantic Scifi - (Logistic recommended by our report)\n",
    "# So let's try logistic\n",
    "\n",
    "df4 = df[(df[\"label\"]==\"romantic\") | (df[\"label\"]==\"scifi\")]\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(\n",
    "    df4[\"processed_synop\"], df4[\"label\"], test_size=0.20, random_state=45)\n",
    "\n",
    "vec4 = TfidfVectorizer()\n",
    "vec4.fit(X_train4)\n",
    "spX_train4 = vec4.transform(X_train4)\n",
    "spX_test4 = vec4.transform(X_test4)\n",
    "\n",
    "log_rs = LogisticRegression()\n",
    "log_rs.fit(spX_train4, y_train4)\n",
    "pred_rs = log_rs.predict(spX_test4)\n",
    "acc_rs = accuracy_score(y_test4, pred_rs)\n",
    "print(f\"Accuracy of log_rs model: {log_rs}\")\n",
    "print(f\"Classification report of log_rs model:\\n{classification_report(y_test4, pred_rs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9024390243902439\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    romantic       0.95      0.86      0.90        21\n",
      "       scifi       0.86      0.95      0.90        20\n",
      "\n",
      "    accuracy                           0.90        41\n",
      "   macro avg       0.91      0.90      0.90        41\n",
      "weighted avg       0.91      0.90      0.90        41\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4th model seems to overfit\n",
    "# Let's try other algorithms\n",
    "nb_rs = MultinomialNB()\n",
    "nb_rs.fit(spX_train4, y_train4)\n",
    "pred_rs = nb_rs.predict(spX_test4)\n",
    "\n",
    "# update the acc_rs here\n",
    "acc_rs = accuracy_score(y_test4, pred_rs)\n",
    "print(f\"Accuracy: {acc_rs}\")\n",
    "print(f\"Classification report:\\n{classification_report(y_test4, pred_rs)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model also seems pretty generalized!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text: Rachel Stone intelligence operative woman stands powerful global peacekeeping organization loss valuable dangerous asset\n",
      "[[0.39567084 0.60432916]]\n"
     ]
    }
   ],
   "source": [
    "# Time to test our fourth model, nb_rs\n",
    "text = \"\"\"Rachel Stone is an intelligence operative, the only woman who stands between her powerful global peacekeeping organization and the loss of its most valuable -- and dangerous -- asset.\"\"\"\n",
    "\n",
    "procesed_txt = preprocess(text=text)\n",
    "print(f\"Processed text: {procesed_txt}\")\n",
    "text_vec = vec4.transform([procesed_txt]) # Use vec4 here\n",
    "output = nb_rs.predict_proba(text_vec)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model also works fine! Let's proceed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of log_rs model: 0.95\n",
      "Classification report of log_rs model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    romantic       1.00      0.90      0.95        20\n",
      "    thriller       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So far we have got four models\n",
    "# log_rd, nb, nb2, and nb_rs\n",
    "# Now for the last pair romantic thriller...\n",
    "# Again we will start with naive bayes, because that's what our report says\n",
    "\n",
    "df5 = df[(df[\"label\"]==\"romantic\") | (df[\"label\"]==\"thriller\")]\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(\n",
    "    df5[\"processed_synop\"], df5[\"label\"], test_size=0.20, random_state=45)\n",
    "\n",
    "vec5 = TfidfVectorizer()\n",
    "vec5.fit(X_train5)\n",
    "spX_train5 = vec5.transform(X_train5)\n",
    "spX_test5 = vec5.transform(X_test5)\n",
    "\n",
    "nb3 = MultinomialNB()\n",
    "nb3.fit(spX_train5, y_train5)\n",
    "pred_nb3 = nb3.predict(spX_test5)\n",
    "acc_nb3 = accuracy_score(y_test5, pred_nb3)\n",
    "print(f\"Accuracy of log_rs model: {acc_nb3}\")\n",
    "print(f\"Classification report of log_rs model:\\n{classification_report(y_test5, pred_nb3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    romantic       0.95      0.90      0.92        20\n",
      "    thriller       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The naive bayes seems to overfit a little\n",
    "# Let's try other algorithms and find a generalized one\n",
    "\n",
    "log_rt = LogisticRegression()\n",
    "log_rt.fit(spX_train5, y_train5)\n",
    "preds_rt = log_rt.predict(spX_test5)\n",
    "acc_rt = accuracy_score(y_test5, preds_rt)\n",
    "print(classification_report(y_test5, preds_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text: Rachel Stone intelligence operative woman stands powerful global peacekeeping organization loss valuable dangerous asset\n",
      "[[0.41964653 0.58035347]]\n"
     ]
    }
   ],
   "source": [
    "# Let's test the last model!\n",
    "text = \"\"\"Rachel Stone is an intelligence operative, the only woman who stands between her powerful global peacekeeping organization and the loss of its most valuable -- and dangerous -- asset.\"\"\"\n",
    "\n",
    "procesed_txt = preprocess(text=text)\n",
    "print(f\"Processed text: {procesed_txt}\")\n",
    "text_vec = vec5.transform([procesed_txt]) # Use vec4 here\n",
    "output = log_rt.predict_proba(text_vec)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model also works fine!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8964634146341464"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have all our models\n",
    "# We have log_rd, nb, nb2, log_rs, log_rt\n",
    "# Let's see take the average of the accuracies of all the 5 models\n",
    "(acc_log + acc_nb + acc_nb2 + acc_rs + acc_rt) / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approximately - 90% good if combined!**\n",
    "**Model variable names are follows:-**\n",
    "1. log_rd (d-r)\n",
    "2. nb (h-r)\n",
    "3. nb2 (a-r)\n",
    "4. nb_rs (r-s)\n",
    "5. log_rt (r-t)\n",
    "\n",
    "Either logistic regression or naive bayes algorithm is used in each pair!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's give a fancy name to combining function\n",
    "# 'Fusionator' sounds good.\n",
    "# For now this version - 0\n",
    "\n",
    "# Pairs:\n",
    "# d-r\n",
    "# h-r\n",
    "# a-r\n",
    "# r-s\n",
    "# r-t\n",
    "\n",
    "def fusionator_v0(best_models, vecs, text):\n",
    "    \"\"\"Fusionator Version - v0\"\"\"\n",
    "    \n",
    "    ptext = preprocess(text)\n",
    "    i = 0\n",
    "    rom_prob = 0\n",
    "    dra_prob = 0\n",
    "    hor_prob = 0\n",
    "    act_prob = 0\n",
    "    sci_prob = 0\n",
    "    thr_prob = 0\n",
    "\n",
    "    while i < len(vecs):\n",
    "        if i <= 2:\n",
    "            ptext_vec = vecs[i].transform([ptext])\n",
    "            prob = best_models[i].predict_proba(ptext_vec)\n",
    "            rom_prob += prob[0][1]\n",
    "\n",
    "            if best_models[i].predict(ptext_vec) == \"drama\":\n",
    "                dra_prob += prob[0][0]\n",
    "            if best_models[i].predict(ptext_vec) == \"horror\":\n",
    "                hor_prob += prob[0][0]\n",
    "            if best_models[i].predict(ptext_vec) == \"action\":\n",
    "                act_prob += prob[0][0]\n",
    "\n",
    "        elif i > 2 and i <= 5:\n",
    "            ptext_vec = vecs[i].transform([ptext])\n",
    "            prob = best_models[i].predict_proba(ptext_vec)\n",
    "\n",
    "            # reverse here (First one belongs to label r)\n",
    "            rom_prob += prob[0][0]\n",
    "            if best_models[i].predict(ptext_vec) == \"scifi\":\n",
    "                sci_prob += prob[0][1]\n",
    "            if best_models[i].predict(ptext_vec) == \"thriller\":\n",
    "                thr_prob += prob[0][1]\n",
    "        i += 1 \n",
    "        # loop ends here\n",
    "    rom_prob = rom_prob / 5\n",
    "    sum_prob = rom_prob + dra_prob + hor_prob + act_prob + sci_prob + thr_prob\n",
    "\n",
    "    rum_prob_f = (rom_prob / sum_prob) * 100\n",
    "    dra_prob_f = (dra_prob / sum_prob) * 100\n",
    "    hor_prob_f = (hor_prob / sum_prob) * 100\n",
    "    act_prob_f = (act_prob / sum_prob) * 100\n",
    "    sci_prob_f = (sci_prob / sum_prob) * 100\n",
    "    thr_prob_f = (thr_prob / sum_prob) * 100\n",
    "\n",
    "    # Final results (combined)\n",
    "    print(f\"Romance: {rum_prob_f}\")\n",
    "    print(f\"Drama: {dra_prob_f}\")\n",
    "    print(f\"Horror: {hor_prob_f}\")\n",
    "    print(f\"Action: {act_prob_f}\")\n",
    "    print(f\"Scifi: {sci_prob_f}\")\n",
    "    print(f\"Thriller: {thr_prob_f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romance: 51.056415478588214\n",
      "Drama: 48.94358452141177\n",
      "Horror: 0.0\n",
      "Action: 0.0\n",
      "Scifi: 0.0\n",
      "Thriller: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the fusionator version v0\n",
    "fusionator_v0(\n",
    "    best_models=[log_rd, nb, nb2, nb_rs, log_rt],\n",
    "    vecs=[vec1, vec2, vec3, vec4, vec5],\n",
    "    text=\"\"\"Henry Barthes (Adrien Brody) is a substitute teacher who shuns emotional connections, and never stays long enough in one district to bond with his students or colleagues. Troubled and lost, Henry lands at a public school where an apathetic student body and disinterested parents have created a frustrated, burned-out group of teachers and administrators. Inadvertently, Henry becomes a role model to his disaffected students and bonds with a teenage runaway who is just as lost as he is.\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Saving the models and vectorizers\n",
    "Some manual test were run on the fusionator version v0 classification system, but it's peformance is average, not that good, not that bad, we can assume around 75%. It can be improved by using word vectors using spacy, or gensim, or maybe fasttext.\n",
    "\n",
    "For now, let's save the models and the vectorizors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/log_rt.pickle']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving all the five models!\n",
    "dump(value=log_rd, filename=\"../models/log_rd.pickle\")\n",
    "dump(value=nb, filename=\"../models/nb.pickle\")\n",
    "dump(value=nb2, filename=\"../models/nb2.pickle\")\n",
    "dump(value=nb_rs, filename=\"../models/nb_rs.pickle\")\n",
    "dump(value=log_rt, filename=\"../models/log_rt.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../vectorizers/vec5.pickle']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving all the five vectorizers (TFIDF)\n",
    "dump(value=vec1, filename=\"../vectorizers/vec1.pickle\")\n",
    "dump(value=vec2, filename=\"../vectorizers/vec2.pickle\")\n",
    "dump(value=vec3, filename=\"../vectorizers/vec3.pickle\")\n",
    "dump(value=vec4, filename=\"../vectorizers/vec4.pickle\")\n",
    "dump(value=vec5, filename=\"../vectorizers/vec5.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
